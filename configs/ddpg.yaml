name: "ddpg"
exp_root_dir: "outputs/${system.environment.name}/${name}"
seed: -1

data:
  type: "dummy-rl-datamodule"
  batch_size: 64
  max_trajectory_length: 1000
  replay_buffer_size: 1000000
  min_replay_buffer_size: 400

system:
  type: "ddpg"
  gamma: 0.99
  soft_update:
    tau: 0.001
    initialize_same_weights: True
  exploration:
    type: "ornstein"
    args:
      delta: 0.15
      sigma: 0.3
      ou_a: 1.0
      ou_mu: 0.0
      seed: -1
  state_action_network:
    type: "mlp"
    args:
      hidden_dim: 400
      n_hidden: 2
      activation_hidden_info:
        type: ReLU
        kwargs: null
      activation_out_info: null

  policy_network:
    type: "mlp"
    args:
      hidden_dim: 400
      n_hidden: 2
      activation_hidden_info:
        type: ReLU
        kwargs: null
      activation_out_info: 
        type: Tanh
        kwargs: null

  environment:
    name: "MountainCarContinuous"
    render: False

  optimizer:
    policy:
      name: Adam
      args:
        lr: 0.0001
        betas: [0.9, 0.99]
    critic:
      name: Adam
      args:
        lr: 0.001
        weight_decay: 0.01

trainer:
  max_episodes: 1000

checkpoint:
  save_last: true # save at each validation time
  save_top_k: 2
  monitor: "${system.environment.name}/Episode Reward"
  every_n_epochs: 10